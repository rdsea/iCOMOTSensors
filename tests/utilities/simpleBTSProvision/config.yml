# a list of distinct broker names
brokers:
  - broker1
  - broker2

# a list of topics that declare how many sensors push to it
sensors:
  - topic: topic1
    nb: 3
    broker: broker1
  - topic: topic2
    nb: 3
    broker: broker2

# a list of ingestion clients that read from selected brokers and their topics
ingestionClients:
  - brokers:
      - brokerId: broker1
        topics: 
          - topic1
<<<<<<< HEAD
=======
    data: default # data plugin to use for ingestionClient
>>>>>>> cf2a084da5f96bbcb85c514781a0e9c861775c32
    
  - brokers:
      - brokerId: broker2
        topics: 
          - topic2
<<<<<<< HEAD
=======
    data: bigQuery
>>>>>>> cf2a084da5f96bbcb85c514781a0e9c861775c32

# the location of the data file as a .csv
# also specifies which of the columns corresponds to the ID of the sensor
data:
<<<<<<< HEAD
  path: '../../data/bts/param-2017-10-23-12-vn.csv'
  sensorId: 'station_id'



=======
  path: './data.csv'
  sensorId: 'station_id'


# configuration for the bigQuery dataplugin, check the ingestion client
bigQuery:
  name: myDataset
  tables:
    - id: params # should be the same as the topic name
      topics:
        - topic1
    # https://cloud.google.com/bigquery/docs/schemas for all BigQuery datatypes and schema definition
      schema:
        - description: description of field
          mode: REQUIRED
          name: id
          type: INTEGER

        - description: description of field
          mode: REQUIRED
          name: value
          type: INTEGER
      
        - description: description of field
          mode: REQUIRED
          name: reading_time
          type: TIMESTAMP

        - description: description of field
          mode: REQUIRED
          name: station_id
          type: INTEGER

        - description: description of field
          mode: REQUIRED
          name: parameter_id
          type: INTEGER
>>>>>>> cf2a084da5f96bbcb85c514781a0e9c861775c32
